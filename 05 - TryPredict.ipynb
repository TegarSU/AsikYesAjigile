{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "import librosa\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path_to_file = 'C:/Users/USER/Downloads/Tugas Akhir/dataset/tes/'\n",
    "# path_to_fitur = \"C:/Users/USER/Downloads/Tugas Akhir/dataset/tes/fitur/\"\n",
    "# path_to_model = \"C:/Users/USER/Downloads/Tugas Akhir/dataset/model/\"\n",
    "\n",
    "path_to_file = 'F:/178/Tugas Akhir/dataset/tes/'\n",
    "path_to_fitur = \"F:/178/Tugas Akhir/dataset/tes/fitur/\"\n",
    "path_to_model = \"F:/178/Tugas Akhir/dataset/model/\"\n",
    "path_to_experiment =\"F:/178/Tugas Akhir/dataset/experiment/\"\n",
    "\n",
    "meanstd = pd.read_csv(path_to_experiment+\"case1_meanstd.csv\",header=None)\n",
    "meanstd = meanstd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Load\n",
    "def load(src):\n",
    "    y, sr = librosa.load(src,mono=True,sr=22050)\n",
    "    \n",
    "    return y,sr\n",
    "\n",
    "# #Convert\n",
    "def convert(filename,path,y,sr):\n",
    "    #Path\n",
    "    dst = path+filename[:-4]+\".wav\"\n",
    "    \n",
    "    #COnver to WAV\n",
    "    librosa.output.write_wav(dst, y, sr)\n",
    "\n",
    "# #Get Feature\n",
    "\n",
    "# #MFCC\n",
    "def mfcc(y,sr,file):\n",
    "    vector = list()\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13) #13 is default dimension 512 frame\n",
    "    data = pd.DataFrame(mfcc)\n",
    "    mean = data.mean(axis = 1).values #Get Mean\n",
    "    std = data.std(axis = 1).values #Get std\n",
    "    vector.append(np.insert(mean,13,std))\n",
    "    save = pd.DataFrame(vector)\n",
    "\n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/mfcc.csv\", index=False, header=False)\n",
    "\n",
    "# #TIMBRE // CENTROID // FLUX // ROLLOFF // ZERO CROSSING \n",
    "def timbre(y,sr,file):\n",
    "    vector = list()\n",
    "    cent = librosa.feature.spectral_centroid(y=y, sr=sr) #1 is default dimension 512 frame\n",
    "    flux = librosa.onset.onset_strength(y=y, sr=sr) #1 is default dimension 512 frame\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr) #1 is default dimension 512 frame\n",
    "    zc = librosa.feature.zero_crossing_rate(y) #1 is default dimension 512 frame\n",
    "    \n",
    "    a = pd.DataFrame(cent) \n",
    "    b = pd.DataFrame(flux).T\n",
    "    c = pd.DataFrame(rolloff)\n",
    "    d = pd.DataFrame(zc)\n",
    "    \n",
    "    frame = [a,b,c,d]\n",
    "    data = pd.concat(frame)\n",
    "    mean = data.mean(axis = 1).values #Get Mean\n",
    "    std = data.std(axis = 1).values #Get std\n",
    "    vector.append(np.insert(mean,4,std))\n",
    "    save = pd.DataFrame(vector)\n",
    "    \n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/timbre.csv\", index=False, header=False)\n",
    "\n",
    "# #SCF and SFM\n",
    "def flatness(y,sr,file):\n",
    "    vector = list()\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    data = pd.DataFrame(flatness)\n",
    "    mean = data.mean(axis = 1).values #Get Mean\n",
    "    std = data.std(axis = 1).values #Get std\n",
    "    vector.append(np.insert(mean,1,std))\n",
    "    save = pd.DataFrame(vector)\n",
    "    \n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/flatness.csv\", index=False, header=False)\n",
    "    \n",
    "def crest(y,sr,file):\n",
    "    peak = y.max()\n",
    "    rms = librosa.feature.rmse(y=y)\n",
    "    n = rms.size\n",
    "    square = rms**2\n",
    "    rms_v2 = math.sqrt((1/n)*(square.sum()))\n",
    "    crest = [peak/rms_v2]\n",
    "    \n",
    "    save = pd.DataFrame(crest)\n",
    "    \n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/crest.csv\", index=False, header=False)\n",
    "\n",
    "# #chroma\n",
    "def chroma(y,sr,file):\n",
    "    vector = list()\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_chroma=12) #24 is default dimension 512 frame\n",
    "    data = pd.DataFrame(chroma)\n",
    "    mean = data.mean(axis = 1).values #Get Mean\n",
    "    std = data.std(axis = 1).values #Get std\n",
    "    vector.append(np.insert(mean,12,std))\n",
    "    save = pd.DataFrame(vector)\n",
    "    \n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/chroma.csv\", index=False, header=False)\n",
    "\n",
    "def fitur(file,y,sr):\n",
    "    \n",
    "    mfccs = mfcc(y,sr,file) #mfcc\n",
    "    timbres = timbre(y,sr,file) #timbre\n",
    "    flatnesss = flatness(y,sr,file) #sfm\n",
    "    crests = crest(y,sr,file) #scf\n",
    "    chromas = chroma(y,sr,file) #chroma\n",
    "    \n",
    "# #merge feature\n",
    "\n",
    "def merge(case1,case2):\n",
    "    case_a = pd.DataFrame(case1)\n",
    "    case_b = pd.DataFrame(case2)\n",
    "    \n",
    "    merged = case_a.merge(case_b, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def flat(song,fitur):\n",
    "    vector = list()\n",
    "    \n",
    "    data = pd.read_csv(path_to_fitur+str(song)+\"/\"+fitur+\".csv\",header=None)\n",
    "    vector.append(np.squeeze(data.values,0))\n",
    "\n",
    "    return vector\n",
    "\n",
    "def norm(data):\n",
    "    result = np.array(data)\n",
    "    mean = meanstd[0]\n",
    "    std = meanstd[1]\n",
    "    normalized = (result-mean)/std\n",
    "\n",
    "def case1(file):\n",
    "    fitur = 'mfcc'\n",
    "    result = flat(file,fitur)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def case2(file):\n",
    "    fitur = 'timbre'\n",
    "    result = flat(file,fitur)\n",
    "    result = np.array(result)\n",
    "    mean = meanstd[1][0]\n",
    "    std = meanstd[1][1]\n",
    "    normalized = (result-mean)/std\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def case3(file):\n",
    "    fitur1 = 'crest'\n",
    "    fitur2 = 'flatness'\n",
    "    crest = flat(file,fitur1)\n",
    "    flatness = flat(file,fitur2)\n",
    "    result = merge(crest,flatness)\n",
    "    result = np.array(result)\n",
    "    mean = meanstd[2][0]\n",
    "    std = meanstd[2][1]\n",
    "    normalized = (result-mean)/std\n",
    "    \n",
    "    return normalized\n",
    "#     result = norm(result)\n",
    "    \n",
    "#     return result\n",
    "\n",
    "def case4(file):\n",
    "    fitur = 'chroma'\n",
    "    result = flat(file,fitur)\n",
    "    result = np.array(result)\n",
    "    mean = meanstd[3][0]\n",
    "    std = meanstd[3][1]\n",
    "    normalized = (result-mean)/std\n",
    "    \n",
    "    return normalized\n",
    "#     result = pd.DataFrame(data=result)\n",
    "#     result = norm(result)\n",
    "    \n",
    "#     return result\n",
    "\n",
    "def case5(file):\n",
    "    case_1 = case1(file)\n",
    "    case_2 = case2(file)\n",
    "    result = merge(case_1,case_2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def case6(file):\n",
    "    case_1 = case1(file)\n",
    "    case_2 = case3(file)\n",
    "    result = merge(case_1,case_2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def case7(file):\n",
    "    case_1 = case1(file)\n",
    "    case_2 = case4(file)\n",
    "    result = merge(case_1,case_2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def case8(file):\n",
    "    case_1 = case5(file)\n",
    "    case_2 = case3(file)\n",
    "    result = merge(case_1,case_2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def case9(file):\n",
    "    case_1 = case5(file)\n",
    "    case_2 = case4(file)\n",
    "    result = merge(case_1,case_2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def case10(file):\n",
    "    case_1 = case8(file)\n",
    "    case_2 = case4(file)\n",
    "    result = merge(case_1,case_2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# #Get emotion\n",
    "\n",
    "def emotion(a,v):\n",
    "    if ((v > 0) & (a >= 0)):\n",
    "        cluster = 'cluster 1'\n",
    "    if ((v <= 0) & (a > 0)):\n",
    "        cluster = 'cluster 2'\n",
    "    if ((v < 0) & (a <= 0)):\n",
    "        cluster = 'cluster 3'\n",
    "    if ((v >= 0) & (a < 0)):\n",
    "        cluster = 'cluster 4'\n",
    "        \n",
    "    return cluster\n",
    "\n",
    "def plot_scatter(a,v):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.xlim(-1,1)\n",
    "    plt.ylim(-1,1)\n",
    "    bbox=dict(boxstyle=\"round\",\n",
    "              ec=(1., 0.5, 0.5),\n",
    "              fc=(1., 0.8, 0.8),\n",
    "              alpha=0.6,\n",
    "              color = 'yellow'\n",
    "           )\n",
    "    plt.text(0.6, 0.7, \"cluster 1\", size=30,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=bbox\n",
    "         )\n",
    "    plt.text(-0.6, 0.7, \"cluster 2\", size=30,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=bbox\n",
    "         )\n",
    "    plt.text(-0.6, -0.7, \"cluster 3\", size=30,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=bbox\n",
    "         )\n",
    "    plt.text(0.6, -0.7, \"cluster 4\", size=30,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=bbox\n",
    "         )\n",
    "\n",
    "    plt.scatter(v,a,color='b')\n",
    "    plt.axhline(y=0,color='black', label =\"X\")\n",
    "    plt.axvline(x=0,color='black', label =\"Y\")\n",
    "    plt.show()\n",
    "    \n",
    "def proses(path):\n",
    "    #Split path\n",
    "    drive, path_and_file = os.path.splitdrive(path)\n",
    "    paths, file = os.path.split(path_and_file)\n",
    "    path_wav = drive+paths+'\\wav\\\\'\n",
    "    path_fitur = drive+paths+'\\fitur\\\\'\n",
    "    #load raw\n",
    "    y, sr = load(path)\n",
    "\n",
    "    #Convert Wav\n",
    "    convert(file,path_wav,y,sr)\n",
    "\n",
    "    #Load Wav\n",
    "    y_wav, sr_wav = load(path_wav+file[:-4]+'.wav')\n",
    "\n",
    "    #make dir\n",
    "    try:  \n",
    "        os.mkdir(path_fitur+file[:-4])\n",
    "    except OSError:  \n",
    "        print (\"Creation of the directory %s failed\" % path_fitur)\n",
    "\n",
    "    # #Feature extraction\n",
    "    fiture = fitur(file[:-4]+'.wav',y_wav,sr_wav)\n",
    "    print(\"feature successfully\")\n",
    "\n",
    "    # #Flatten\n",
    "    results = case1(file[:-4])\n",
    "    print(\"flatten successfully\")\n",
    "\n",
    "    # #Norm\n",
    "    results = norm(results)\n",
    "    \n",
    "    # #Load Model\n",
    "\n",
    "    arousal = path_to_model+'arousal/case1.sav'\n",
    "    valence = path_to_model+'valence/case1.sav'\n",
    "\n",
    "    arousal_model = joblib.load(arousal)\n",
    "    valence_model = joblib.load(valence)\n",
    "\n",
    "    a = arousal_model.predict(results)\n",
    "    v = valence_model.predict(results)\n",
    "    \n",
    "    emo = emotion(a,v)\n",
    "    \n",
    "#     return v,a,normalized\n",
    "    return a,v,emo,results\n",
    "\n",
    "#     emo = emotion(a,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory F:\\178\\Tugas Akhir\\dataset\\tes\f",
      "itur\\ failed\n",
      "feature successfully\n",
      "flatten successfully\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=None.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-529f0ec91ee7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0memo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F:\\\\178\\\\Tugas Akhir\\\\dataset\\\\tes\\\\939.mp3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0memo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-29ef59590bcc>\u001b[0m in \u001b[0;36mproses\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[0mvalence_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marousal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalence_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, return_std, return_cov)\u001b[0m\n\u001b[0;32m    312\u001b[0m                 \"returning full covariance.\")\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"X_train_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Unfitted;predict based on GP prior\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    543\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    546\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=None.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "a,v,emo,normalized = proses(\"F:\\\\178\\\\Tugas Akhir\\\\dataset\\\\tes\\\\939.mp3\")\n",
    "print(a.round(2),v.round(2),emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1e-10,\n",
       " 'copy_X_train': True,\n",
       " 'kernel': 1.17**2 * RationalQuadratic(alpha=0.022, length_scale=4.78),\n",
       " 'kernel__k1': 1.17**2,\n",
       " 'kernel__k1__constant_value': 1.362172982755161,\n",
       " 'kernel__k1__constant_value_bounds': (1e-05, 100000.0),\n",
       " 'kernel__k2': RationalQuadratic(alpha=0.022, length_scale=4.78),\n",
       " 'kernel__k2__alpha': 0.02203730709759159,\n",
       " 'kernel__k2__alpha_bounds': (1e-06, 1000000.0),\n",
       " 'kernel__k2__length_scale': 4.7836885154724067,\n",
       " 'kernel__k2__length_scale_bounds': (1e-06, 1000000.0),\n",
       " 'n_restarts_optimizer': 10,\n",
       " 'normalize_y': True,\n",
       " 'optimizer': 'fmin_l_bfgs_b',\n",
       " 'random_state': 1000}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 [ 0.08][ 0.21] 1 \n",
    "#2 [-0.13][ 0.03] 4 \n",
    "#3 [ 0.01][ 0.08] 1 \n",
    "#4 [-0.37][-0.12] 3 [-0.02][ 0.15]  4\n",
    "#5 [ 0.06][ 0.17] 1 [ 0.36][ 0.23] 1\n",
    "#6 [ 0.07][ 0.24] 1 [ 0.34][ 0.24] 1\n",
    "#7 [-0.32] [-0.67] cluster 3\n",
    "#8 [-0.25] [-0.52] cluster 3\n",
    "#9 [-0.28] [-0.49] cluster 3 [-0.3] [-0.44] cluster 3\n",
    "#10 [-0.28] [-0.44] cluster 3 [-0.3] [-0.38] cluster 3\n",
    "\n",
    "\n",
    "#Load Model\n",
    "\n",
    "arousal = path_to_model+'arousal/case1.sav'\n",
    "valence = path_to_model+'valence/case1.sav'\n",
    "\n",
    "arousal_model = joblib.load(arousal)\n",
    "valence_model = joblib.load(valence)\n",
    "arousal_model.get_params()\n",
    "# a = arousal_model.predict(result)\n",
    "# v = valence_model.predict(result)\n",
    "\n",
    "# emo = emotion(a,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for filename in os.listdir(path_to_file):\n",
    "#     if os.path.isfile(os.path.join(path_to_file, filename)):\n",
    "        \n",
    "#         #load raw\n",
    "#         y, sr = load(path_to_file+filename)\n",
    "\n",
    "#         #Convert Wav\n",
    "#         convert(filename,path_dst,y,sr)\n",
    "        \n",
    "#         #Load Wav\n",
    "#         y_wav, sr_wav = load(path_to_file+'wav/'+file)\n",
    "\n",
    "#         #make dir\n",
    "#         try:  \n",
    "#             os.mkdir(path_to_fitur+filename[:-4])\n",
    "#         except OSError:  \n",
    "#             print (\"Creation of the directory %s failed\" % path_to_fitur)\n",
    "        \n",
    "#         # #Feature extraction\n",
    "#         fiture = fitur(filename[:-4]+'.wav',y_wav,sr_wav)\n",
    "#         print(\"feature successfully\")\n",
    "        \n",
    "#         # #Flatten\n",
    "#         results = case4(filename[:-4])\n",
    "#         print(\"flatten successfully\")\n",
    "        \n",
    "#         # #Norm\n",
    "#         normalized = norm(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
