{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "import librosa\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path_to_file = 'C:/Users/USER/Downloads/Tugas Akhir/dataset/tes/'\n",
    "# path_to_fitur = \"C:/Users/USER/Downloads/Tugas Akhir/dataset/tes/fitur/\"\n",
    "# path_to_model = \"C:/Users/USER/Downloads/Tugas Akhir/dataset/model/\"\n",
    "\n",
    "path_to_file = 'F:/178/Tugas Akhir/dataset/tes/'\n",
    "path_to_fitur = \"F:/178/Tugas Akhir/dataset/tes/fitur/\"\n",
    "path_to_model = \"F:/178/Tugas Akhir/dataset/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Load\n",
    "def load(src):\n",
    "    y, sr = librosa.load(src,mono=True,sr=22050)\n",
    "    \n",
    "    return y,sr\n",
    "\n",
    "# #Convert\n",
    "def convert(filename,path,y,sr):\n",
    "    #Path\n",
    "    dst = path+filename[:-4]+\".wav\"\n",
    "    \n",
    "    #COnver to WAV\n",
    "    librosa.output.write_wav(dst, y, sr)\n",
    "\n",
    "# #Get Feature\n",
    "\n",
    "# #MFCC\n",
    "def mfcc(y,sr,file):\n",
    "    vector = list()\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13) #13 is default dimension 512 frame\n",
    "    data = pd.DataFrame(mfcc)\n",
    "    mean = data.mean(axis = 1).values #Get Mean\n",
    "    std = data.std(axis = 1).values #Get std\n",
    "    vector.append(np.insert(mean,13,std))\n",
    "    save = pd.DataFrame(vector)\n",
    "\n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/mfcc.csv\", index=False, header=False)\n",
    "\n",
    "# #TIMBRE // CENTROID // FLUX // ROLLOFF // ZERO CROSSING \n",
    "def timbre(y,sr,file):\n",
    "    vector = list()\n",
    "    cent = librosa.feature.spectral_centroid(y=y, sr=sr) #1 is default dimension 512 frame\n",
    "    flux = librosa.onset.onset_strength(y=y, sr=sr) #1 is default dimension 512 frame\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr) #1 is default dimension 512 frame\n",
    "    zc = librosa.feature.zero_crossing_rate(y) #1 is default dimension 512 frame\n",
    "    \n",
    "    a = pd.DataFrame(cent) \n",
    "    b = pd.DataFrame(flux).T\n",
    "    c = pd.DataFrame(rolloff)\n",
    "    d = pd.DataFrame(zc)\n",
    "    \n",
    "    frame = [a,b,c,d]\n",
    "    data = pd.concat(frame)\n",
    "    mean = data.mean(axis = 1).values #Get Mean\n",
    "    std = data.std(axis = 1).values #Get std\n",
    "    vector.append(np.insert(mean,4,std))\n",
    "    save = pd.DataFrame(vector)\n",
    "    \n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/timbre.csv\", index=False, header=False)\n",
    "\n",
    "# #SCF and SFM\n",
    "def flatness(y,sr,file):\n",
    "    vector = list()\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    data = pd.DataFrame(flatness)\n",
    "    mean = data.mean(axis = 1).values #Get Mean\n",
    "    std = data.std(axis = 1).values #Get std\n",
    "    vector.append(np.insert(mean,1,std))\n",
    "    save = pd.DataFrame(vector)\n",
    "    \n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/flatness.csv\", index=False, header=False)\n",
    "    \n",
    "def crest(y,sr,file):\n",
    "    peak = y.max()\n",
    "    rms = librosa.feature.rmse(y=y)\n",
    "    n = rms.size\n",
    "    square = rms**2\n",
    "    rms_v2 = math.sqrt((1/n)*(square.sum()))\n",
    "    crest = [peak/rms_v2]\n",
    "    \n",
    "    save = pd.DataFrame(crest)\n",
    "    \n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/crest.csv\", index=False, header=False)\n",
    "\n",
    "# #chroma\n",
    "def chroma(y,sr,file):\n",
    "    vector = list()\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_chroma=24) #24 is default dimension 512 frame\n",
    "    data = pd.DataFrame(chroma)\n",
    "    mean = data.mean(axis = 1).values #Get Mean\n",
    "    std = data.std(axis = 1).values #Get std\n",
    "    vector.append(np.insert(mean,12,std))\n",
    "    save = pd.DataFrame(vector)\n",
    "    \n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/chroma.csv\", index=False, header=False)\n",
    "\n",
    "def fitur(file,y,sr):\n",
    "    \n",
    "    mfccs = mfcc(y,sr,file) #mfcc\n",
    "    timbres = timbre(y,sr,file) #timbre\n",
    "    flatnesss = flatness(y,sr,file) #sfm\n",
    "    crests = crest(y,sr,file) #scf\n",
    "    chromas = chroma(y,sr,file) #chroma\n",
    "    \n",
    "# #merge feature\n",
    "\n",
    "def merge(case1,case2):\n",
    "    case_a = pd.DataFrame(case1)\n",
    "    case_b = pd.DataFrame(case2)\n",
    "    \n",
    "    merged = case_a.merge(case_b, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def flat(song,fitur):\n",
    "    vector = list()\n",
    "    \n",
    "    data = pd.read_csv(path_to_fitur+str(song)+\"/\"+fitur+\".csv\",header=None)\n",
    "    vector.append(np.squeeze(data.values,0))\n",
    "        \n",
    "#     result = np.array(vector)\n",
    "#     mean = result.mean()\n",
    "#     std = result.std()\n",
    "\n",
    "#     normalized = (result-mean)/std\n",
    "\n",
    "    return vector\n",
    "\n",
    "def case1(file):\n",
    "    fitur = 'mfcc'\n",
    "    result = flat(file,fitur)\n",
    "    df = pd.DataFrame(result)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def case2(file):\n",
    "    case_1 = case1(file)\n",
    "    fitur = 'timbre'\n",
    "    case_2 = flat(file,fitur)\n",
    "    result = merge(case_1,case_2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def case3(file):\n",
    "    case_2 = case2(file)\n",
    "    fitur1 = 'crest'\n",
    "    fitur2 = 'flatness'\n",
    "    crest = flat(file,fitur1)\n",
    "    flatness = flat(file,fitur2)\n",
    "    results = merge(case_2,crest)\n",
    "    result = merge(results,flatness)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def case4(file):\n",
    "    case_3 = case3(file)\n",
    "    fitur = 'chroma'\n",
    "    chroma = flat(file,fitur)\n",
    "    result = merge(case_3,chroma)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def norm(data):\n",
    "    result = np.array(data)\n",
    "    mean = result.mean()\n",
    "    std = result.std()\n",
    "\n",
    "    normalized = (result-mean)/std\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "# #Get emotion\n",
    "\n",
    "def emotion(a,v):\n",
    "    if ((v >= 0) & (a > 0)):\n",
    "        cluster = 'cluster 1'\n",
    "    if ((v < 0) & (a >= 0)):\n",
    "        cluster = 'cluster 2'\n",
    "    if ((v <= 0) & (a < 0)):\n",
    "        cluster = 'cluster 3'\n",
    "    if ((v > 0) & (a <= 0)):\n",
    "        cluster = 'cluster 4'\n",
    "        \n",
    "    return cluster\n",
    "\n",
    "def plot_scatter(a,v):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.xlim(-1,1)\n",
    "    plt.ylim(-1,1)\n",
    "    bbox=dict(boxstyle=\"round\",\n",
    "              ec=(1., 0.5, 0.5),\n",
    "              fc=(1., 0.8, 0.8),\n",
    "              alpha=0.6,\n",
    "              color = 'yellow'\n",
    "           )\n",
    "    plt.text(0.6, 0.7, \"cluster 1\", size=30,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=bbox\n",
    "         )\n",
    "    plt.text(-0.6, 0.7, \"cluster 2\", size=30,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=bbox\n",
    "         )\n",
    "    plt.text(-0.6, -0.7, \"cluster 3\", size=30,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=bbox\n",
    "         )\n",
    "    plt.text(0.6, -0.7, \"cluster 4\", size=30,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=bbox\n",
    "         )\n",
    "\n",
    "    plt.scatter(v,a,color='b')\n",
    "    plt.axhline(y=0,color='black', label =\"X\")\n",
    "    plt.axvline(x=0,color='black', label =\"Y\")\n",
    "    plt.show()\n",
    "    \n",
    "def proses(path):\n",
    "    #Split path\n",
    "    drive, path_and_file = os.path.splitdrive(path)\n",
    "    paths, file = os.path.split(path_and_file)\n",
    "    path_wav = drive+paths+'\\wav\\\\'\n",
    "    path_fitur = drive+paths+'\\fitur\\\\'\n",
    "    #load raw\n",
    "    y, sr = load(path)\n",
    "\n",
    "    #Convert Wav\n",
    "    convert(file,path_wav,y,sr)\n",
    "\n",
    "    #Load Wav\n",
    "    y_wav, sr_wav = load(path_wav+file[:-4]+'.wav')\n",
    "\n",
    "    #make dir\n",
    "    try:  \n",
    "        os.mkdir(path_fitur+file[:-4])\n",
    "    except OSError:  \n",
    "        print (\"Creation of the directory %s failed\" % path_fitur)\n",
    "\n",
    "    # #Feature extraction\n",
    "    fiture = fitur(file[:-4]+'.wav',y_wav,sr_wav)\n",
    "    print(\"feature successfully\")\n",
    "\n",
    "    # #Flatten\n",
    "    results = case2(file[:-4])\n",
    "    print(\"flatten successfully\")\n",
    "\n",
    "    # #Norm\n",
    "    normalized = norm(results)\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory F:\\178\\Tugas Akhir\\dataset\\tes\f",
      "itur\\ failed\n",
      "feature successfully\n",
      "flatten successfully\n"
     ]
    }
   ],
   "source": [
    "result = proses(\"F:\\\\178\\\\Tugas Akhir\\\\dataset\\\\tes\\\\939.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.44792649, -0.27475053, -0.30349522, -0.31501785, -0.30677625,\n",
       "        -0.32131381, -0.32740569, -0.32328168, -0.32105444, -0.31633375,\n",
       "        -0.32627783, -0.32467106, -0.32133783, -0.24018128, -0.2828006 ,\n",
       "        -0.29978846, -0.30535536, -0.30389239, -0.30725565, -0.3092024 ,\n",
       "        -0.30845772, -0.31225251, -0.31171987, -0.31194833, -0.31220434,\n",
       "        -0.31258117,  2.20811279, -0.31906704,  4.79579167, -0.32035404,\n",
       "         0.89331997, -0.31904255,  1.52888765, -0.32036592]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9666cb919c9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mvalence_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marousal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalence_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, return_std, return_cov)\u001b[0m\n\u001b[0;32m    312\u001b[0m                 \"returning full covariance.\")\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"X_train_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Unfitted;predict based on GP prior\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "#Load Model\n",
    "\n",
    "arousal = path_to_model+'arousal/case4.sav'\n",
    "valence = path_to_model+'valence/case4.sav'\n",
    "\n",
    "arousal_model = joblib.load(arousal)\n",
    "valence_model = joblib.load(valence)\n",
    "\n",
    "a = arousal_model.predict(result)\n",
    "v = valence_model.predict(result)\n",
    "\n",
    "emo = emotion(a,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert successfully\n",
      "Creation of the directory F:/178/Tugas Akhir/dataset/tes/fitur/ failed\n",
      "feature successfully\n",
      "flatten successfully\n"
     ]
    }
   ],
   "source": [
    "# for filename in os.listdir(path_to_file):\n",
    "#     if os.path.isfile(os.path.join(path_to_file, filename)):\n",
    "        \n",
    "#         #load raw\n",
    "#         y, sr = load(path_to_file+filename)\n",
    "\n",
    "#         #Convert Wav\n",
    "#         convert(filename,path_dst,y,sr)\n",
    "        \n",
    "#         #Load Wav\n",
    "#         y_wav, sr_wav = load(path_to_file+'wav/'+file)\n",
    "\n",
    "#         #make dir\n",
    "#         try:  \n",
    "#             os.mkdir(path_to_fitur+filename[:-4])\n",
    "#         except OSError:  \n",
    "#             print (\"Creation of the directory %s failed\" % path_to_fitur)\n",
    "        \n",
    "#         # #Feature extraction\n",
    "#         fiture = fitur(filename[:-4]+'.wav',y_wav,sr_wav)\n",
    "#         print(\"feature successfully\")\n",
    "        \n",
    "#         # #Flatten\n",
    "#         results = case4(filename[:-4])\n",
    "#         print(\"flatten successfully\")\n",
    "        \n",
    "#         # #Norm\n",
    "#         normalized = norm(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:\t F:/178/Tugas Akhir/dataset/tes/wav/Peterpan - Walau Habis Terang.wav \n",
      "arousal:\t [ 6.71026819] \n",
      "valence:\t [ 5.40794292] \n",
      "cluster:\t cluster 1\n"
     ]
    }
   ],
   "source": [
    "print('filename:\\t',dst,'\\narousal:\\t',a,'\\nvalence:\\t',v,'\\ncluster:\\t',emo) #peterpan case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:\t F:/178/Tugas Akhir/dataset/tes/wav/Adele - Someone Like You.wav \n",
      "arousal:\t [ 4.8227413] \n",
      "valence:\t [ 4.89320867] \n",
      "cluster:\t cluster 3\n"
     ]
    }
   ],
   "source": [
    "print('filename:\\t',dst,'\\narousal:\\t',a,'\\nvalence:\\t',v,'\\ncluster:\\t',emo) #adele case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
