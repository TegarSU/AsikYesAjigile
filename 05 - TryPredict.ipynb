{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "import librosa\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path_to_file = 'C:/Users/USER/Downloads/Tugas Akhir/dataset/tes/'\n",
    "# path_to_fitur = \"C:/Users/USER/Downloads/Tugas Akhir/dataset/tes/fitur/\"\n",
    "# path_to_model = \"C:/Users/USER/Downloads/Tugas Akhir/dataset/model/\"\n",
    "\n",
    "path_to_file = 'F:/178/Tugas Akhir/dataset/tes/'\n",
    "path_to_fitur = \"F:/178/Tugas Akhir/dataset/tes/fitur/\"\n",
    "path_to_model = \"F:/178/Tugas Akhir/dataset/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Load\n",
    "def load(src):\n",
    "    y, sr = librosa.load(src,mono=True,sr=22050)\n",
    "    \n",
    "    return y,sr\n",
    "\n",
    "# #Convert\n",
    "def convert(filename,path,y,sr):\n",
    "    #Path\n",
    "    dst = path+filename[:-4]+\".wav\"\n",
    "    \n",
    "    #COnver to WAV\n",
    "    librosa.output.write_wav(dst, y, sr)\n",
    "\n",
    "# #Get Feature\n",
    "\n",
    "# #MFCC\n",
    "def mfcc(y,sr,file):\n",
    "    vector = list()\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13) #13 is default dimension 512 frame\n",
    "    data = pd.DataFrame(mfcc)\n",
    "    mean = data.mean(axis = 1).values #Get Mean\n",
    "    std = data.std(axis = 1).values #Get std\n",
    "    vector.append(np.insert(mean,13,std))\n",
    "    save = pd.DataFrame(vector)\n",
    "\n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/mfcc.csv\", index=False, header=False)\n",
    "\n",
    "# #TIMBRE // CENTROID // FLUX // ROLLOFF // ZERO CROSSING \n",
    "def timbre(y,sr,file):\n",
    "    vector = list()\n",
    "    cent = librosa.feature.spectral_centroid(y=y, sr=sr) #1 is default dimension 512 frame\n",
    "    flux = librosa.onset.onset_strength(y=y, sr=sr) #1 is default dimension 512 frame\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr) #1 is default dimension 512 frame\n",
    "    zc = librosa.feature.zero_crossing_rate(y) #1 is default dimension 512 frame\n",
    "    \n",
    "    a = pd.DataFrame(cent) \n",
    "    b = pd.DataFrame(flux).T\n",
    "    c = pd.DataFrame(rolloff)\n",
    "    d = pd.DataFrame(zc)\n",
    "    \n",
    "    frame = [a,b,c,d]\n",
    "    data = pd.concat(frame)\n",
    "    mean = data.mean(axis = 1).values #Get Mean\n",
    "    std = data.std(axis = 1).values #Get std\n",
    "    vector.append(np.insert(mean,4,std))\n",
    "    save = pd.DataFrame(vector)\n",
    "    \n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/timbre.csv\", index=False, header=False)\n",
    "\n",
    "# #SCF and SFM\n",
    "def flatness(y,sr,file):\n",
    "    vector = list()\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    data = pd.DataFrame(flatness)\n",
    "    mean = data.mean(axis = 1).values #Get Mean\n",
    "    std = data.std(axis = 1).values #Get std\n",
    "    vector.append(np.insert(mean,1,std))\n",
    "    save = pd.DataFrame(vector)\n",
    "    \n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/flatness.csv\", index=False, header=False)\n",
    "    \n",
    "def crest(y,sr,file):\n",
    "    peak = y.max()\n",
    "    rms = librosa.feature.rmse(y=y)\n",
    "    n = rms.size\n",
    "    square = rms**2\n",
    "    rms_v2 = math.sqrt((1/n)*(square.sum()))\n",
    "    crest = [peak/rms_v2]\n",
    "    \n",
    "    save = pd.DataFrame(crest)\n",
    "    \n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/crest.csv\", index=False, header=False)\n",
    "\n",
    "# #chroma\n",
    "def chroma(y,sr,file):\n",
    "    vector = list()\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_chroma=12) #24 is default dimension 512 frame\n",
    "    data = pd.DataFrame(chroma)\n",
    "    mean = data.mean(axis = 1).values #Get Mean\n",
    "    std = data.std(axis = 1).values #Get std\n",
    "    vector.append(np.insert(mean,12,std))\n",
    "    save = pd.DataFrame(vector)\n",
    "    \n",
    "    save.to_csv(path_to_fitur+file[:-4]+\"/chroma.csv\", index=False, header=False)\n",
    "\n",
    "def fitur(file,y,sr):\n",
    "    \n",
    "    mfccs = mfcc(y,sr,file) #mfcc\n",
    "    timbres = timbre(y,sr,file) #timbre\n",
    "    flatnesss = flatness(y,sr,file) #sfm\n",
    "    crests = crest(y,sr,file) #scf\n",
    "    chromas = chroma(y,sr,file) #chroma\n",
    "    \n",
    "# #merge feature\n",
    "\n",
    "def merge(case1,case2):\n",
    "    case_a = pd.DataFrame(case1)\n",
    "    case_b = pd.DataFrame(case2)\n",
    "    \n",
    "    merged = case_a.merge(case_b, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def flat(song,fitur):\n",
    "    vector = list()\n",
    "    \n",
    "    data = pd.read_csv(path_to_fitur+str(song)+\"/\"+fitur+\".csv\",header=None)\n",
    "    vector.append(np.squeeze(data.values,0))\n",
    "\n",
    "    return vector\n",
    "\n",
    "def case1(file):\n",
    "    fitur = 'mfcc'\n",
    "    result = flat(file,fitur)\n",
    "    df = pd.DataFrame(result)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def case2(file):\n",
    "    case_1 = case1(file)\n",
    "    fitur = 'timbre'\n",
    "    case_2 = flat(file,fitur)\n",
    "    result = merge(case_1,case_2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def case3(file):\n",
    "    case_2 = case2(file)\n",
    "    fitur1 = 'crest'\n",
    "    fitur2 = 'flatness'\n",
    "    crest = flat(file,fitur1)\n",
    "    flatness = flat(file,fitur2)\n",
    "    results = merge(case_2,crest)\n",
    "    result = merge(results,flatness)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def case4(file):\n",
    "    case_3 = case3(file)\n",
    "    fitur = 'chroma'\n",
    "    chroma = flat(file,fitur)\n",
    "    result = merge(case_3,chroma)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def norm(data):\n",
    "    result = np.array(data)\n",
    "    mean = result.mean()\n",
    "    std = result.std()\n",
    "\n",
    "    normalized = (result-mean)/std\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "# #Get emotion\n",
    "\n",
    "def emotion(a,v):\n",
    "    if ((v > 0) & (a >= 0)):\n",
    "        cluster = 'cluster 1'\n",
    "    if ((v <= 0) & (a > 0)):\n",
    "        cluster = 'cluster 2'\n",
    "    if ((v < 0) & (a <= 0)):\n",
    "        cluster = 'cluster 3'\n",
    "    if ((v >= 0) & (a < 0)):\n",
    "        cluster = 'cluster 4'\n",
    "        \n",
    "    return cluster\n",
    "\n",
    "def plot_scatter(a,v):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.xlim(-1,1)\n",
    "    plt.ylim(-1,1)\n",
    "    bbox=dict(boxstyle=\"round\",\n",
    "              ec=(1., 0.5, 0.5),\n",
    "              fc=(1., 0.8, 0.8),\n",
    "              alpha=0.6,\n",
    "              color = 'yellow'\n",
    "           )\n",
    "    plt.text(0.6, 0.7, \"cluster 1\", size=30,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=bbox\n",
    "         )\n",
    "    plt.text(-0.6, 0.7, \"cluster 2\", size=30,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=bbox\n",
    "         )\n",
    "    plt.text(-0.6, -0.7, \"cluster 3\", size=30,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=bbox\n",
    "         )\n",
    "    plt.text(0.6, -0.7, \"cluster 4\", size=30,\n",
    "         ha=\"center\", va=\"center\",\n",
    "         bbox=bbox\n",
    "         )\n",
    "\n",
    "    plt.scatter(v,a,color='b')\n",
    "    plt.axhline(y=0,color='black', label =\"X\")\n",
    "    plt.axvline(x=0,color='black', label =\"Y\")\n",
    "    plt.show()\n",
    "    \n",
    "def proses(path):\n",
    "    #Split path\n",
    "    drive, path_and_file = os.path.splitdrive(path)\n",
    "    paths, file = os.path.split(path_and_file)\n",
    "    path_wav = drive+paths+'\\wav\\\\'\n",
    "    path_fitur = drive+paths+'\\fitur\\\\'\n",
    "    #load raw\n",
    "    y, sr = load(path)\n",
    "\n",
    "    #Convert Wav\n",
    "    convert(file,path_wav,y,sr)\n",
    "\n",
    "    #Load Wav\n",
    "    y_wav, sr_wav = load(path_wav+file[:-4]+'.wav')\n",
    "\n",
    "    #make dir\n",
    "    try:  \n",
    "        os.mkdir(path_fitur+file[:-4])\n",
    "    except OSError:  \n",
    "        print (\"Creation of the directory %s failed\" % path_fitur)\n",
    "\n",
    "    # #Feature extraction\n",
    "    fiture = fitur(file[:-4]+'.wav',y_wav,sr_wav)\n",
    "    print(\"feature successfully\")\n",
    "\n",
    "    # #Flatten\n",
    "    results = case4(file[:-4])\n",
    "    print(\"flatten successfully\")\n",
    "\n",
    "    # #Norm\n",
    "    normalized = norm(results)\n",
    "    \n",
    "    # #Load Model\n",
    "\n",
    "    arousal = path_to_model+'arousal/case4.sav'\n",
    "    valence = path_to_model+'valence/case4.sav'\n",
    "\n",
    "    arousal_model = joblib.load(arousal)\n",
    "    valence_model = joblib.load(valence)\n",
    "\n",
    "    a = arousal_model.predict(normalized)\n",
    "    v = valence_model.predict(normalized)\n",
    "    \n",
    "    return v,a,normalized\n",
    "\n",
    "#     emo = emotion(a,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory F:\\178\\Tugas Akhir\\dataset\\tes\f",
      "itur\\ failed\n",
      "feature successfully\n",
      "flatten successfully\n",
      "[ 0.03546424] [ 0.06303378]\n"
     ]
    }
   ],
   "source": [
    "v,a,normalized = proses(\"F:\\\\178\\\\Tugas Akhir\\\\dataset\\\\tes\\\\939.mp3\")\n",
    "print(v,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40123516, -0.17436114, -0.21201893, -0.22711447, -0.21631734,\n",
       "        -0.23536267, -0.24334351, -0.23794073, -0.23502287, -0.2288384 ,\n",
       "        -0.24186593, -0.23976093, -0.23539413, -0.12907272, -0.18490736,\n",
       "        -0.20716278, -0.21445586, -0.21253925, -0.21694539, -0.21949578,\n",
       "        -0.21852018, -0.22349165, -0.22279385, -0.22309316, -0.22342855,\n",
       "        -0.22392223,  3.07838357, -0.23241923,  6.46844483, -0.23410529,\n",
       "         1.35590237, -0.23238714,  2.18854562, -0.23412086, -0.2266885 ,\n",
       "        -0.23422704, -0.2342127 , -0.23374873, -0.233826  , -0.23396537,\n",
       "        -0.23398459, -0.23400574, -0.2340055 , -0.23399544, -0.23398187,\n",
       "        -0.23394542, -0.23389349, -0.23384538, -0.23382258, -0.23394234,\n",
       "        -0.23394722, -0.23397674, -0.23397432, -0.2339969 , -0.23398323,\n",
       "        -0.23399808, -0.23399478, -0.23399258, -0.23397716, -0.23394951,\n",
       "        -0.23395771]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [-0.38665231][-0.75646618] [ 0.06427516][-0.03813184] [ 0.11686378][-0.00219273] [ 0.20947236][ 0.12625835]\n",
    "# [-0.31986225][-0.6172328] [ 0.04008732][-0.06173782] [ 0.0858818][-0.0337648] [ 0.16975319][ 0.08035165]\n",
    "# [-0.16978618] [-0.3717958]\n",
    "#Load Model\n",
    "\n",
    "# arousal = path_to_model+'arousal/case1.sav'\n",
    "# valence = path_to_model+'valence/case2.sav'\n",
    "\n",
    "# arousal_model = joblib.load(arousal)\n",
    "# valence_model = joblib.load(valence)\n",
    "# valence_model.get_params()\n",
    "# a = arousal_model.predict(result)\n",
    "# v = valence_model.predict(result)\n",
    "\n",
    "# emo = emotion(a,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for filename in os.listdir(path_to_file):\n",
    "#     if os.path.isfile(os.path.join(path_to_file, filename)):\n",
    "        \n",
    "#         #load raw\n",
    "#         y, sr = load(path_to_file+filename)\n",
    "\n",
    "#         #Convert Wav\n",
    "#         convert(filename,path_dst,y,sr)\n",
    "        \n",
    "#         #Load Wav\n",
    "#         y_wav, sr_wav = load(path_to_file+'wav/'+file)\n",
    "\n",
    "#         #make dir\n",
    "#         try:  \n",
    "#             os.mkdir(path_to_fitur+filename[:-4])\n",
    "#         except OSError:  \n",
    "#             print (\"Creation of the directory %s failed\" % path_to_fitur)\n",
    "        \n",
    "#         # #Feature extraction\n",
    "#         fiture = fitur(filename[:-4]+'.wav',y_wav,sr_wav)\n",
    "#         print(\"feature successfully\")\n",
    "        \n",
    "#         # #Flatten\n",
    "#         results = case4(filename[:-4])\n",
    "#         print(\"flatten successfully\")\n",
    "        \n",
    "#         # #Norm\n",
    "#         normalized = norm(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
